<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>STT Test - PCM 16-bit</title>
  <style>
    body.recording {
      background-color: #fffae6;
    }
    #transcript {
      white-space: pre-wrap;
      border: 1px solid #ccc;
      padding: 10px;
      margin-top: 20px;
      height: 150px;
      overflow-y: auto;
    }
    #status {
      margin-top: 10px;
      font-weight: bold;
      color: #444;
    }
    button { margin-right: 10px; }
  </style>
</head>
<body>
  <h1>ðŸŽ¤ STT Microphone Test (PCM 16-bit)</h1>
  <button id="start">Start</button>
  <button id="stop" disabled>Stop</button>

  <div id="transcript"></div>
  <div id="status"></div>

  <script>
    let ws;
    let stream;
    let audioContext;
    let processor;
    let source;
    let reconnectTimeout = null;
    const transcriptDiv = document.getElementById('transcript');
    const statusDiv = document.getElementById('status');
    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');

    function logStatus(msg) {
      console.log(msg);
      statusDiv.textContent = msg;
    }

    async function startRecording() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioContext = new AudioContext({ sampleRate: 48000 });
        source = audioContext.createMediaStreamSource(stream);

        processor = audioContext.createScriptProcessor(4096, 1, 1);
        source.connect(processor);
        processor.connect(audioContext.destination);

        setupWebSocket();

        processor.onaudioprocess = (e) => {
          if (!ws || ws.readyState !== WebSocket.OPEN) return;

          const inputData = e.inputBuffer.getChannelData(0);
          const pcmBuffer = convertFloat32ToInt16(inputData);
          ws.send(pcmBuffer);
        };

        logStatus("ðŸŽ™ï¸ Recording started (PCM 16-bit)");
        document.body.classList.add("recording");
        startBtn.disabled = true;
        stopBtn.disabled = false;

      } catch (err) {
        console.error("âŒ Error accessing microphone:", err);
        logStatus("âŒ Error accessing microphone");
      }
    }

    function stopRecording() {
      if (reconnectTimeout) { clearTimeout(reconnectTimeout); reconnectTimeout = null; }
      processor?.disconnect();
      source?.disconnect();
      stream?.getTracks().forEach(track => track.stop());
      ws?.close();
      document.body.classList.remove("recording");
      logStatus("ðŸ›‘ Recording stopped");
      startBtn.disabled = false;
      stopBtn.disabled = true;
    }

    function convertFloat32ToInt16(buffer) {
      const l = buffer.length;
      const result = new Int16Array(l);
      for (let i = 0; i < l; i++) {
        let s = Math.max(-1, Math.min(1, buffer[i]));
        result[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
      }
      return result.buffer;
    }

    function setupWebSocket() {
      if (ws) { ws.close(); ws = null; }

      ws = new WebSocket(`wss://${window.location.host}`);
      ws.binaryType = "arraybuffer";

      ws.onopen = () => {
        logStatus("âœ… WebSocket connection opened");
        if (reconnectTimeout) { clearTimeout(reconnectTimeout); reconnectTimeout = null; }
      };

      ws.onmessage = (event) => {
        if (!event.data) return;

        let messageData = event.data;
        if (messageData instanceof ArrayBuffer) {
          messageData = new TextDecoder('utf-8').decode(messageData);
        }

        try {
          const data = JSON.parse(messageData);
          console.log("RAW data from server:", data);

          if (data.type === "Transcript" || data.type === "PartialTranscript") {
            const transcript = data.channel?.alternatives?.[0]?.transcript || '';
            const isFinal = data.is_final || data.speech_final || false;

            if (transcript) {
              console.log("ðŸ“ Transcription:", transcript);
              transcriptDiv.textContent += transcript + (isFinal ? " âœ”ï¸\n" : " â€¦\n");
              transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
            }
          }

          if (data.metadata) {
            console.log("â„¹ï¸ Metadata:", data.metadata);
          }
        } catch (e) {
          console.error("âŒ Error parsing message:", e);
        }
      };

      ws.onerror = (err) => { console.error("âš ï¸ WebSocket error:", err); logStatus("âš ï¸ WebSocket error"); };
      ws.onclose = (event) => {
        logStatus(`ðŸ”Œ WebSocket closed (code: ${event.code}, reason: ${event.reason || 'No reason'})`);
        if (stream && stream.getAudioTracks().length > 0 && !reconnectTimeout) {
          reconnectTimeout = setTimeout(() => { logStatus("ðŸ”„ Reconnecting WebSocket..."); setupWebSocket(); }, 1000);
        }
      };
    }

    startBtn.onclick = () => startRecording();
    stopBtn.onclick = () => stopRecording();
  </script>
</body>
</html>
