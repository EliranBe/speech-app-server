<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Realtime STT with Interim Results</title>
  <style>
    body { font-family: monospace; background: #f4f4f4; padding: 20px; }
    #log { background: #fff; padding: 10px; border: 1px solid #ccc; height: 400px; overflow-y: scroll; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h1>Realtime STT with Interim Results</h1>
  <button id="start">Start</button>
  <pre id="log"></pre>

  <script>
    const logEl = document.getElementById('log');
    const log = (msg) => {
      console.log(msg);
      logEl.textContent += msg + "\n";
      logEl.scrollTop = logEl.scrollHeight;
    };

    let ws, audioContext, processor, source;

    // פונקציה להמרת float32 ל-Int16PCM
    function floatTo16BitPCM(buffer) {
      const l = buffer.length;
      const buf = new Int16Array(l);
      for (let i = 0; i < l; i++) {
        let s = Math.max(-1, Math.min(1, buffer[i]));
        buf[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      return buf.buffer;
    }

    async function start() {
      if (ws && ws.readyState === WebSocket.OPEN) {
        log("WebSocket already open");
        return;
      }

      ws = new WebSocket("wss://speech-app-server.onrender.com");
      ws.binaryType = "arraybuffer";

      ws.onopen = async () => {
        log("✅ WebSocket opened");

        try {
          audioContext = new AudioContext({ sampleRate: 16000 });
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          source = audioContext.createMediaStreamSource(stream);
          processor = audioContext.createScriptProcessor(4096, 1, 1);

          processor.onaudioprocess = e => {
            const floatData = e.inputBuffer.getChannelData(0);
            const int16Data = floatTo16BitPCM(floatData);
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(int16Data);
              log(`⬆ Sent audio chunk (${int16Data.byteLength} bytes)`);
            }
          };

          source.connect(processor);
          processor.connect(audioContext.destination);

          log("🎙️ Audio streaming started");
        } catch (err) {
          log("❌ Error accessing microphone or AudioContext: " + err.message);
        }
      };

      ws.onmessage = event => {
        try {
          const data = JSON.parse(event.data);
          if (data.type === "keepalive") return;
          const transcript = data.channel.alternatives[0].transcript;
          const prefix = data.is_final ? "✅ Final" : "⏳ Interim";
          log(`${prefix}: ${transcript}`);
        } catch (e) {
          log("⚠️ Non-JSON message: " + event.data);
        }
      };

      ws.onerror = err => log("❌ WS error: " + err.message);
      ws.onclose = () => log("🔌 WS closed");
    }

    document.getElementById("start").onclick = start;
  </script>
</body>
</html>
