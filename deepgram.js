const WebSocket = require('ws');
const { createClient, LiveTranscriptionEvents } = require('@deepgram/sdk');
const express = require('express'); // ×× ×¦×¨×™×š app

const { translateText } = require('./azure-translator'); // ×©×™××•×© ×‘×¤×•× ×§×¦×™×™×ª ×”×ª×¨×’×•×

const { synthesizeTextToBase64 } = require('./google-tts'); // ×©×™××•×© ×‘×¤×•× ×§×¦×™×™×ª ×”×§×•×œ×™×ª

module.exports = function startWebSocketServer(server, app) {
  const wss = new WebSocket.Server({ server }); // server ××’×™×¢ ×-index.js

  const deepgramApiKey = process.env.DEEPGRAM_API_KEY;
  if (!deepgramApiKey) {
    throw new Error("âš ï¸ Missing DEEPGRAM_API_KEY in environment variables");
  }

  const deepgramClient = createClient(deepgramApiKey);

const setupDeepgram = (ws, getLastChunkTime, pendingItemsRef, checkClose) => {
    const deepgram = deepgramClient.listen.live({
      model: 'nova-3',
      smart_format: true,
      language: 'multi',
      dictation: true, 
      punctuate: true,
      utterances: true,
      diarize: true,
      numerals: true,
      paragraphs: true,
      interim_results: false,
      endpointing: 100,
      vad_events: true
    });

    let keepAlive = setInterval(() => {
    console.log("deepgram: keepalive");
    deepgram.keepAlive();
  }, 10 * 1000);

    deepgram.addListener(LiveTranscriptionEvents.Open, async() => {
      console.log("ğŸ”— deepgram: connected");
});
deepgram.addListener(LiveTranscriptionEvents.Transcript, async (data) => {
  const last = typeof getLastChunkTime === 'function' ? getLastChunkTime() : null;
  const latency = last ? (Date.now() - last) : null;      
  console.log("ğŸ“¦ Full transcript event:", JSON.stringify(data, null, 2));
        console.log("âœ… WebSocket received transcript from deepgram", latency ? `Latency: ${latency} ms` : '');
        console.log("âœ… WebSocket sent transcript to client");
  
    // × ×©×œ×— ×œ×œ×§×•×— ××ª ×”×ª××œ×•×œ ×”××§×•×¨×™ ×™×©×™×¨×•×ª (×›×“×™ ×œ×”×ª××™× ×œ×¦×“ ×”×œ×§×•×—)
try {
  pendingItemsRef.value++;
  ws.send(JSON.stringify(data));
} catch (err) {
  console.error("âŒ Error sending transcript:", err);
} finally {
  pendingItemsRef.value--;
  checkClose();
}

  // ×›××Ÿ × ×’×“×™×¨ ×¤×¢× ××—×ª ××ª ×©×¤×ª ×”××§×•×¨ ×•×©×¤×ª ×”×™×¢×“
const sourceLang = "en";  // ×”×©×¤×” ×‘×” ××ª×” ××“×‘×¨
const targetLang = "ru";  // ×”×©×¤×” ×œ-TTS ×•×ª×¨×’×•×
  
    // × ×ª×¨×’× ××ª ×”×ª××œ×•×œ 
  const transcriptText = data?.channel?.alternatives?.[0]?.transcript;
   let translated = null;
  if (transcriptText) {
         try {
           pendingItemsRef.value++; // âœ… ×”×ª×—×œ× ×• ×ª×”×œ×™×š ×ª×¨×’×•×
      translated = await translateText(transcriptText, targetLang, sourceLang);
      console.log("ğŸŒ Translated text:", translated);

      // ×©×•×œ×— ×œ×œ×§×•×— ×”×•×“×¢×” ×—×“×©×” ×¢× ×”×ª×¨×’×•×
      ws.send(JSON.stringify({
        type: "translation",
        payload: { original: transcriptText, translated }
      }));
           pendingItemsRef.value--; // âœ… ×ª×”×œ×™×š ×ª×¨×’×•× ×”×¡×ª×™×™×
           checkClose();
    } catch (err) {
      console.error("âŒ Translation error:", err);
    }
    if (translated) {
      try {
      // ×™×•×¦×¨ ××•×“×™×• ×‘-Google TTS ××”×ª×¨×’×•×
      const textForTTS = translated?.[targetLang] || "";
        console.log("ğŸ“¢ Sending to Google TTS:", textForTTS);
        pendingItemsRef.value++; // âœ… ×”×ª×—×œ× ×• ×ª×”×œ×™×š TTS
    const audioBase64 = await synthesizeTextToBase64(textForTTS);
    // ×©×•×œ×— ×œ×œ×§×•×— ××ª ×”××•×“×™×•
  ws.send(JSON.stringify({
    type: "tts",
    payload: { audioBase64 }
  }));
       pendingItemsRef.value--; // âœ… ×ª×”×œ×™×š TTS ×”×¡×ª×™×™×
        checkClose();
} catch (err) {
  console.error("âŒ Google TTS error:", err);
  }
}
}
});
    
      deepgram.addListener(LiveTranscriptionEvents.Close, async() => {
        console.log("deepgram: disconnected");
        clearInterval(keepAlive);
      });

      deepgram.addListener(LiveTranscriptionEvents.Error, async(error) => {
        console.log("âš ï¸ deepgram: error received");
        console.error(error);
      });

      deepgram.addListener(LiveTranscriptionEvents.Warning, async(warning) => {
        console.log("âš ï¸ deepgram: warning received");
        console.warn(warning);
      });

      deepgram.addListener(LiveTranscriptionEvents.Metadata, (data) => {
        const detectedLang = data?.detected_language || "unknown";
        const tier = data?.tier || "unknown";
        const models = data?.models || "-";
        console.log(`deepgram: metadata received â€“ Detected language: ${detectedLang}, Tier: ${tier}, Models: ${models}`);
        ws.send(JSON.stringify({ metadata: data }));
      });
    

    return { deepgram, keepAlive };
  };// <-- ×¡×•×£ setupDeepgram

  wss.on('connection', (ws) => {
    console.log("ğŸ”— Client connected to WebSocket");
  let lastChunkTime = null;
const getLastChunkTime = () => lastChunkTime;
      let isRecording = true; // âœ… ×‘×¨×™×¨×ª ××—×“×œ - ××§×œ×™×˜×™×
      let pendingItemsRef = { value: 0 }; // ××¡×¤×¨ ×¤×¨×™×˜×™× ×‘×”××ª× ×” ×œ×©×œ×™×—×” ×œ×œ×§×•×—
      let stopRequested = false;
      let { deepgram, keepAlive } = setupDeepgram(ws, getLastChunkTime, pendingItemsRef, checkClose);
 
ws.on('message', (message) => {
  // × × ×¡×” ×œ×¤×¨×© ×× ×–×• ×”×•×“×¢×ª ×©×œ×™×˜×” (stop) ××• ××•×“×™×•
  let parsed;
  try {
    parsed = JSON.parse(message.toString());
  } catch (e) {
    parsed = null;
  }

  // âœ… ×”×•×“×¢×ª ×©×œ×™×˜×” ××”×œ×§×•×—
if (parsed && parsed.type === "control") {
  if (parsed.action === "stop") {
    console.log("â¸ï¸ Recording stopped by client");
    isRecording = false; // ××¤×¡×™×§×™× ×œ×©×œ×•×— ××•×“×™×• ×—×“×©
    stopRequested = true; // ×—×“×©: ××¦×™×™×Ÿ ×©×¦×¨×™×š ×œ×”×¤×¡×™×§ ×¨×§ ××—×¨×™ ×©×”×›×•×œ ×”×’×™×¢ ×œ×œ×§×•×—
  }
  return; // ×œ× ×œ×©×œ×•×— ×”×•×“×¢×•×ª ×©×œ×™×˜×” ×œÖ¾Deepgram
}

  // âœ… ×¨×§ ×× ×¢×“×™×™×Ÿ ××§×œ×™×˜×™× - × ×©×œ×— ××ª ×”××•×“×™×• ×œÖ¾Deepgram
  console.log('Received audio chunk, size:', message.length); // ğŸŸ¢ ×—×–×¨× ×• ×œ×”×“×¤×™×¡ ×’× ××ª ×”×’×•×“×œ
  if (isRecording && deepgram.getReadyState() === 1) {
    lastChunkTime = Date.now();
    console.log("âœ… WebSocket sent audio chunk to deepgram");
    deepgram.send(message);
  } else if (!isRecording) {
    console.log("âš ï¸ Recording paused, audio chunk ignored");
  } else if (deepgram.getReadyState() >= 2) { // CLOSING / CLOSED
    console.log("âš ï¸ WebSocket couldn't be sent data to deepgram");
    console.log("âš ï¸ Deepgram connection closed, retrying...");
    deepgram.finish();
    deepgram.removeAllListeners();
    if (keepAlive) {
      clearInterval(keepAlive);
      keepAlive = null;
    }
({ deepgram, keepAlive } = setupDeepgram(ws, getLastChunkTime, pendingItemsRef, checkClose));
  } else {
    console.log("âš ï¸ Deepgram socket not ready (probably CONNECTING state)"); 
  }
});
     
    ws.on('close', () => {
      console.log("âŒ Client disconnected from WebSocket");
    if (keepAlive) {
    clearInterval(keepAlive);
    keepAlive = null;
  }
  // ××‘×˜×™×— ×©×›×œ ×”×§×‘×¦×™× ×©×›×‘×¨ ×”×ª×§×‘×œ×• ×™×¢×•×‘×“×•
 if (deepgram) {
  if (!stopRequested || pendingItemsRef.value === 0) {
    deepgram.finish();             // ××¡×™×™× ×ª××œ×•×œ ×¨×§ ×›×©×‘×××ª ××•×ª×¨
    deepgram.removeAllListeners();
  }
}
  });

    function checkClose() {
  if (stopRequested && pendingItemsRef.value === 0) {
    if (ws.readyState === WebSocket.OPEN) {
      ws.close();
      console.log("ğŸ”Œ WebSocket closed after all processing finished");
    }
  }
}

}; // ×¡×•×£ startWebSocketServer

